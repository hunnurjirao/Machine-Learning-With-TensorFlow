{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graduate_Admission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFhDMQENgrdD",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hunnurjirao/Machine-Learning-With-TensorFlow/blob/master/Projects/Graduate_Admission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS9b5BkAT0Y5",
        "colab_type": "text"
      },
      "source": [
        "# **Graduate Admission**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPy02K9RT8_w",
        "colab_type": "text"
      },
      "source": [
        "The goal of the Project is all about the Prediction of Graduate Admissions. This dataset was takn from the Kaggle here https://www.kaggle.com/tags/linear-regression . The dataset contains several parameters which are considered important during the application for Masters Programs.\n",
        "\n",
        "**The parameters included are :** \n",
        "\n",
        "1.GRE Scores ( out of 340 )\n",
        "\n",
        "2.TOEFL Scores ( out of 120 )\n",
        "\n",
        "3.University Rating ( out of 5 )\n",
        "\n",
        "4.Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n",
        "\n",
        "5.Undergraduate GPA ( out of 10 )\n",
        "\n",
        "6.Research Experience ( either 0 or 1 )\n",
        "\n",
        "7.Chance of Admit ( ranging from 0 to 1 )\n",
        "\n",
        "As discussed in this tutorial http://deeplearningprojectshub.co/index.html/ML03.html, we are using TensorFlow to solve this Linear Regression Problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HrqJPUkZWnF",
        "colab_type": "text"
      },
      "source": [
        "### Importing Necessary modules\n",
        "We will start asusual by importing our necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW2NtG9O8Bl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "02f5d806-620b-4118-f7ee-769c0f958277"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4NBeMWkbN-P",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlTRDLWUZf1H",
        "colab_type": "text"
      },
      "source": [
        "Load the datasets, that contains columns [Serial No.,\tGRE Score,\tTOEFL Score,\tUniversity Rating,\tSOP,\tLOR,\tCGPA,\tResearch,\tChance of Admit\n",
        " ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Th2Pm4Z1fs",
        "colab_type": "text"
      },
      "source": [
        "Here every feature is important fot this problem except the Serial No. which dosen't affect the Chance of Admit of the Student. So we will exclude that from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbCE3GpzihuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "fed7f152-9d88-4a3c-d9b5-cd6b69bf3543"
      },
      "source": [
        "df = pd.read_csv(\"Graduate_Admission.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  ...  CGPA  Research  Chance of Admit \n",
              "0           1        337          118  ...  9.65         1              0.92\n",
              "1           2        324          107  ...  8.87         1              0.76\n",
              "2           3        316          104  ...  8.00         1              0.72\n",
              "3           4        322          110  ...  8.67         1              0.80\n",
              "4           5        314          103  ...  8.21         0              0.65\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhBJhFdDaPiq",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing\n",
        "Data Preprocessing is very much important while going to train our model. Here we have conformed that there are no null values in our dataframe. So we are good to go to train our model. If there are any null values, make sure that you fill that null values with mean or median of that specific data column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ytiae8ci6lZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b5b5fb18-1aeb-440d-a0b9-c26be5d99492"
      },
      "source": [
        "df.isnull().any()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Serial No.           False\n",
              "GRE Score            False\n",
              "TOEFL Score          False\n",
              "University Rating    False\n",
              "SOP                  False\n",
              "LOR                  False\n",
              "CGPA                 False\n",
              "Research             False\n",
              "Chance of Admit      False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkzCc-LhkQH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,1:8]\n",
        "\n",
        "y = df[\"Chance of Admit \"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzDMSAEBknD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.asarray(X)\n",
        "y = np.asarray(y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-dK8aEvlQTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eaa9738-5bd4-471d-b1da-c9c9eaa88e39"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST_CYT2mlRNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95b43a4c-1480-42e7-8de8-f320d5aea911"
      },
      "source": [
        "y = y.reshape(400,1)\n",
        "y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6Nk06qQvdBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test =train_test_split(X,y,test_size = 0.33)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL7iMf3XbW1c",
        "colab_type": "text"
      },
      "source": [
        "Now we will use the TensorFlow operations that we have learned in here  http://deeplearningprojectshub.co/index.html/ML03.html. Here we have created placeholders and variables for further use. We have also done linear operation i.e. Y = m * X + c. Note that here X is the matrix of features  and Y is the matrix of target. Our goal is to find the matrix m that contains the slope values and also to find the y-intercept c."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzKncB9flSV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = tf.placeholder(shape = [None,7], dtype = tf.float32)\n",
        "y_target = tf.placeholder(shape = [None,1], dtype = tf.float32)\n",
        "\n",
        "A = tf.Variable(tf.random_normal([7,1]))\n",
        "b = tf.Variable(tf.random_normal([1,1]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxwC0WYBmlMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_output = tf.add(tf.matmul(x_data,A),b)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGs1s8QithYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# elastic_param1 = tf.constant(1.)\n",
        "# elastic_param2 = tf.constant(1.)\n",
        "# l1_a_loss = tf.reduce_mean(tf.abs(A))\n",
        "# l2_a_loss = tf.reduce_mean(tf.square(A))\n",
        "# e1_term = tf.multiply(elastic_param1, l1_a_loss)\n",
        "# e2_term = tf.multiply(elastic_param2, l2_a_loss)\n",
        "# loss = tf.expand_dims(tf.add(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), e1_term), e2_term), 0)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Idgqx05cg0k",
        "colab_type": "text"
      },
      "source": [
        "### Loss and Optimizers\n",
        "\n",
        "Here we used L1 loss which is absolute difference between the predicted and actual values and similarly we used Gradient Descent Optiizer with learning rate 0.00001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfP0ZqTomxx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.abs(model_output - y_target))\n",
        "\n",
        "my_optim = tf.train.GradientDescentOptimizer(learning_rate = 0.00001)\n",
        "optimizer = my_optim.minimize(loss)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3KDIRnWnRE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH0Jqe3Jc7Zn",
        "colab_type": "text"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "Now we will start our training loop. loss_vals stores the loss value at each iteration and here we used batch_size = 64.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPqUoeiGdM3h",
        "colab_type": "text"
      },
      "source": [
        "Instead of training all the examples at a time, here we are training 64 examples at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRYULAg1ndq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "f50250f7-0da3-4292-be2d-18d603fa7629"
      },
      "source": [
        "loss_vals = []\n",
        "batch_size = 64\n",
        "for i in range(500):\n",
        "  rand_index = np.random.choice(len(x_train), size=batch_size)\n",
        "\n",
        "  rand_X = x_train[rand_index]\n",
        "  rand_y = (y_train[rand_index])\n",
        "  rand_y = rand_y.reshape(batch_size,1)\n",
        "  sess.run(optimizer, feed_dict = {x_data: rand_X, y_target: rand_y})\n",
        "  temp_loss = sess.run(loss, feed_dict = {x_data: rand_X, y_target: rand_y})\n",
        "\n",
        "  loss_vals.append(temp_loss)\n",
        "  if (i+1)%50==0:\n",
        "    print('Step: ' + str(i+1) + '  loss: ' + str(temp_loss) )\n",
        "\n",
        "print(' A = ' + str(sess.run(A)) + ' b = ' + str(sess.run(b)) + '  Loss: ' + str(temp_loss))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 50  loss: 395.74857\n",
            "Step: 100  loss: 338.2331\n",
            "Step: 150  loss: 284.2125\n",
            "Step: 200  loss: 227.84654\n",
            "Step: 250  loss: 171.99542\n",
            "Step: 300  loss: 115.91063\n",
            "Step: 350  loss: 60.667587\n",
            "Step: 400  loss: 4.7648053\n",
            "Step: 450  loss: 1.1509173\n",
            "Step: 500  loss: 1.1963086\n",
            " A = [[-0.01952957]\n",
            " [ 0.09871853]\n",
            " [-0.2572442 ]\n",
            " [-0.37538677]\n",
            " [-1.3363227 ]\n",
            " [ 0.1879764 ]\n",
            " [ 1.1095754 ]] b = [[0.80133146]]  Loss: 1.1963086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrtZga0mddrN",
        "colab_type": "text"
      },
      "source": [
        "OOh! we got loss = 1.1 approx. Not Bad!\n",
        "\n",
        "Whatever, now let us plot the loss graph w.r.t number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIWRbQQLqB-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "28594721-ebcb-4946-b41d-93ddc0d81e33"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_vals, 'k-')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi3NxDNFdrUc",
        "colab_type": "text"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EWpOQ4Bdv7Y",
        "colab_type": "text"
      },
      "source": [
        "Here, we used sigmoid function, because out output varies from 0 to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wN4awaNeBHT",
        "colab_type": "text"
      },
      "source": [
        "Finally the model predicted as 91 members are admitted for Graduation where really 122 members are admitted for Graduation. Similarly model predicted as 41 members are not admitted for Graduation where really 10 members are not admitted for Graduation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvfcSGvAyQq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = sess.run(tf.nn.sigmoid(model_output),feed_dict={x_data: x_test})\n",
        "\n",
        "ypred_pos=0\n",
        "ypred_neg=0\n",
        "\n",
        "for i in range(len(a)):\n",
        "  if a[i] > 0.5:\n",
        "    ypred_pos = ypred_pos + 1\n",
        "  else:\n",
        "    ypred_neg = ypred_neg + 1\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNmmD8ATWDAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3e76d8a5-74e1-4617-b803-5c3d5db1c110"
      },
      "source": [
        "print(\"Model predicted as admitted for Graduation: \" + str(ypred_pos))\n",
        "print(\"Model predicted as not admitted for Graduation: \" + str(ypred_neg))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model predicted as admitted for Graduation: 91\n",
            "Model predicted as not admitted for Graduation: 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiXatKnbUF9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytest_pos=0\n",
        "ytest_neg=0\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] > 0.5:\n",
        "    ytest_pos = ytest_pos + 1\n",
        "  else:\n",
        "    ytest_neg = ytest_neg + 1\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnAotB5wV-b8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0e5c1392-818c-4463-ae7d-9f25f9ad56e9"
      },
      "source": [
        "print(\"Actually admitted for Graduation: \" + str(ytest_pos))\n",
        "print(\"Actually not admitted for Graduation: \" + str(ytest_neg))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actually admitted for Graduation: 122\n",
            "Actually not admitted for Graduation: 10\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}